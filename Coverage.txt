Absolutely, I can help you craft a prompt for that! It sounds like you want GitHub Copilot (or a similar code-generation tool) to analyze your repository and help you generate test cases to improve code coverage. Let’s put that into a neat zero-shot instruction prompt.

⸻

Prompt for GitHub Copilot to Improve Code Coverage

Role:
Act as a code coverage assistant integrated with GitHub Copilot. Your task is to help increase test coverage for a repository containing LLM-generated solutions.

Goal:
Analyze all scripts and existing test cases in the repository and suggest additional test scenarios to reach over 80% code coverage. The repository contains multiple scripts that need thorough unit tests to meet CI/CD acceptance criteria.

Context:
	•	The repository includes scripts generated by language models.
	•	Existing tests are present but not sufficient for the required coverage.
	•	The acceptance criteria is to reach more than 80% test coverage, or else the CI/CD pipeline will fail.

Your Task:
	1.	Analyze Code and Tests: Review the provided scripts and their existing test cases.
	2.	Suggest Additional Tests: Identify missing test scenarios and edge cases that would improve coverage.
	3.	Generate Test Code: Provide sample unit tests or test code snippets to be added to the repository.
	4.	Explain Coverage Impact: Briefly explain how the suggested tests will raise the coverage percentage.

Output Format:
	•	Overview: Summarize the current coverage gaps.
	•	New Test Scenarios: List of new test cases to add.
	•	Code Snippets: Example test functions or unit tests.
	•	Coverage Estimate: Expected improvement in coverage.

⸻

This way, GitHub Copilot will know exactly what role it’s playing and what kind of outputs you’re looking for. Let me know if you want any adjustments!
